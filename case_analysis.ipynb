{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7093a0-659b-4dcf-9f6f-c712500ffe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d908b466-fabd-40b3-ab62-ef3959190c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output directories\n",
    "#MOT17 video = 'MOT17-02-DPM'\n",
    "#UrbanTracker video= 'rene_video'\n",
    "tracking_outputs_dir = r\"C:\\Users\\User\\Documents\\vision\\UrbanTracker\\rouen_video\"\n",
    "#image_folder = r\"C:\\Users\\User\\Documents\\MOT17\\MOT17\\train\\MOT17-02-DPM\\img1\"  # Folder with extracted images\n",
    "output_dir = r\"C:\\Users\\User\\Documents\\vision\\UrbanTracker\\rouen_video\\analysis_results\"\n",
    "\n",
    "video_path = r\"C:\\Users\\User\\Documents\\vision\\UrbanTracker\\rouen_video\\rouen_video.avi\"  # Path to your video file\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f89332-fb84-46fb-a218-1bd9b6207229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gt\n",
    "gt_df = pd.read_csv(r\"C:\\Users\\User\\Documents\\vision\\UrbanTracker\\rouen_video\\gt.txt\")\n",
    "gt_df = gt_df.iloc[:, 0:6]\n",
    "gt_df.columns = ['frame', 'gt_id', 'x', 'y', 'w', 'h']\n",
    "gt_df[['frame', 'x', 'y', 'w', 'h']] = gt_df[['frame', 'x', 'y', 'w', 'h']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b68a7b1-d0d6-4c2d-afa7-431989289513",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_threshold = 0.4\n",
    "\n",
    "# IoU calculation function\n",
    "def compute_iou(boxA, boxB):\n",
    "    # Convert (x, y, w, h) => (x1, y1, x2, y2)\n",
    "    xA1, yA1, wA, hA = boxA\n",
    "    xB1, yB1, wB, hB = boxB\n",
    "    xA2, yA2 = xA1 + wA, yA1 + hA\n",
    "    xB2, yB2 = xB1 + wB, yB1 + hB\n",
    "\n",
    "    # Compute intersection rectangle\n",
    "    inter_x1 = max(xA1, xB1)\n",
    "    inter_y1 = max(yA1, yB1)\n",
    "    inter_x2 = min(xA2, xB2)\n",
    "    inter_y2 = min(yA2, yB2)\n",
    "    inter_w = max(0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0, inter_y2 - inter_y1)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    # Compute union area\n",
    "    areaA = wA * hA\n",
    "    areaB = wB * hB\n",
    "    union_area = areaA + areaB - inter_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008af5c1-3f0d-407a-8c36-e4cb9cae6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bad_frames_by_threshold(matches_df, top_n=3):\n",
    "\n",
    "    # Count how many bad matches are in each frame\n",
    "    frame_error_counts = matches_df.groupby('frame').size().sort_values(ascending=False)\n",
    "\n",
    "    # Select top N worst frames by number of bad matches\n",
    "    top_bad_frame_ids = frame_error_counts.head(top_n).index.tolist()\n",
    "\n",
    "    # Return the full match data for these frames\n",
    "    return matches_df[matches_df['frame'].isin(top_bad_frame_ids)].sort_values(by=['frame', 'iou'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94995942-1027-4051-bccb-cc72b1cac592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw bounding boxes\n",
    "def draw_boxes(image, boxes, color, label_prefix):\n",
    "    for box in boxes:\n",
    "        x, y, w, h = int(box['x']), int(box['y']), int(box['w']), int(box['h'])\n",
    "        obj_id = int(box['id'])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, f\"{label_prefix} {obj_id}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da3e1dd-76f0-49d8-9cc0-a2b12c34af78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536d9f05fcc84ce48d86a6cda096e20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all relevant CSV files that match the YOLO tracking output pattern\n",
    "csv_files = [f for f in os.listdir(tracking_outputs_dir) if f.startswith(\"yolo_tracking_output\") and f.endswith(\".csv\")]\n",
    "\n",
    "# Loop through each file and process it\n",
    "for file in tqdm(csv_files):\n",
    "    model_name = file.replace(\"yolo_tracking_output_\", \"\").replace(\".csv\", \"\")\n",
    "    file_path = os.path.join(tracking_outputs_dir, file)\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    yolo_df = pd.read_csv(file_path,header=0)\n",
    "    yolo_df.columns = ['frame', 'yolo_id', 'x', 'y', 'w', 'h']\n",
    "    yolo_df[['frame', 'x', 'y', 'w', 'h']] = yolo_df[['frame', 'x', 'y', 'w', 'h']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Match YOLO predictions to GT by frame and IoU\n",
    "    matches = []\n",
    "    \n",
    "    # Go frame by frame\n",
    "    for frame in sorted(yolo_df['frame'].unique()):\n",
    "        yolo_frame = yolo_df[yolo_df['frame'] == frame]\n",
    "        gt_frame = gt_df[gt_df['frame'] == frame]\n",
    "    \n",
    "        # For each YOLO detection in the frame\n",
    "        for _, yolo_row in yolo_frame.iterrows():\n",
    "            best_iou = 0\n",
    "            best_gt_id = None\n",
    "            yolo_box = [yolo_row['x'], yolo_row['y'], yolo_row['w'], yolo_row['h']]\n",
    "    \n",
    "            # Compare to each GT box in the same frame\n",
    "            for _, gt_row in gt_frame.iterrows():\n",
    "                gt_box = [gt_row['x'], gt_row['y'], gt_row['w'], gt_row['h']]\n",
    "                iou = compute_iou(yolo_box, gt_box)\n",
    "    \n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_id = gt_row['gt_id']\n",
    "    \n",
    "            # Save if IoU is above threshold\n",
    "            if best_iou >= iou_threshold:\n",
    "                matches.append({\n",
    "                    'frame': frame,\n",
    "                    'yolo_id': yolo_row['yolo_id'],\n",
    "                    'gt_id': best_gt_id,\n",
    "                    'iou': best_iou\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame and save or display\n",
    "    matches_df = pd.DataFrame(matches)\n",
    "\n",
    "    # Get the top n worst frames based on the chosen threshold\n",
    "    top_bad_frames_custom = get_top_bad_frames_by_threshold(matches_df, top_n=3)\n",
    "    top_bad_frames_custom.to_csv(os.path.join(output_dir, f\"{model_name}_top_bad_frames_custom.csv\"), index=False)\n",
    "    worst_frame_ids = top_bad_frames_custom['frame'].unique()\n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Failed to open video: {video_path}\")\n",
    "    \n",
    "    # Loop over each bad frame\n",
    "    for frame_id in worst_frame_ids:\n",
    "        # Set video to the specific frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            #print(f\"Frame not found: {frame_id}\")\n",
    "            continue\n",
    "    \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # Get GT and YOLO boxes for current frame\n",
    "        gt_boxes = gt_df[gt_df['frame'] == frame_id][['x', 'y', 'w', 'h', 'gt_id']].rename(columns={'gt_id': 'id'})\n",
    "        yolo_boxes = yolo_df[yolo_df['frame'] == frame_id][['x', 'y', 'w', 'h', 'yolo_id']].rename(columns={'yolo_id': 'id'})\n",
    "    \n",
    "        # 1. GT only\n",
    "        gt_img = draw_boxes(img_rgb.copy(), gt_boxes.to_dict('records'), (0, 255, 0), 'GT')\n",
    "        plt.imshow(gt_img)\n",
    "        plt.title(f\"Frame {frame_id} – Ground Truth\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(output_dir, f\"{model_name}Frame{frame_id}_GroundTruth.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "        # 2. YOLO only\n",
    "        yolo_img = draw_boxes(img_rgb.copy(), yolo_boxes.to_dict('records'), (255, 0, 0), 'YOLO')\n",
    "        plt.imshow(yolo_img)\n",
    "        plt.title(f\"Frame {frame_id} – YOLO Prediction\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(output_dir, f\"{model_name}Frame{frame_id}_YOLO.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "        # 3. Combined\n",
    "        combined_img = draw_boxes(img_rgb.copy(), gt_boxes.to_dict('records'), (0, 255, 0), 'GT')\n",
    "        combined_img = draw_boxes(combined_img, yolo_boxes.to_dict('records'), (255, 0, 0), 'YOLO')\n",
    "        plt.imshow(combined_img)\n",
    "        plt.title(f\"Frame {frame_id} – GT (green) vs YOLO (red)\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(output_dir, f\"{model_name}Frame{frame_id}_Combined.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf2e7a-abc7-42ee-a686-ab211eee3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
